{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1548b098",
   "metadata": {},
   "source": [
    "## 3. Sentiment Analysis and other graphs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "137dac9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\rapha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\rapha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Data management\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "# Databases\n",
    "import sqlalchemy as alch\n",
    "from getpass import getpass\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Languages\n",
    "import re\n",
    "\n",
    "import spacy\n",
    "\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from langdetect import detect\n",
    "from textblob import TextBlob\n",
    "\n",
    "from NLP import NLP\n",
    "nlp = NLP()\n",
    "\n",
    "import stylecloud\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "\n",
    "# Visualization\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab3b196",
   "metadata": {},
   "source": [
    "### We bring all the data to a dataframe from MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24540bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Introduce your password: ········\n"
     ]
    }
   ],
   "source": [
    "password = getpass(\"Introduce your password: \")\n",
    "dbName = \"starwars\"\n",
    "connectionData=f\"mysql+pymysql://root:{password}@localhost/{dbName}\"\n",
    "engine = alch.create_engine(connectionData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27100a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character_</th>\n",
       "      <th>text_</th>\n",
       "      <th>episode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>THREEPIO</td>\n",
       "      <td>Did you hear that  Theyve shut down the main r...</td>\n",
       "      <td>episode IV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>THREEPIO</td>\n",
       "      <td>Were doomed</td>\n",
       "      <td>episode IV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>THREEPIO</td>\n",
       "      <td>Therell be no escape for the Princess this time.</td>\n",
       "      <td>episode IV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>THREEPIO</td>\n",
       "      <td>Whats that</td>\n",
       "      <td>episode IV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>THREEPIO</td>\n",
       "      <td>I should have known better than to trust the l...</td>\n",
       "      <td>episode IV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2518</th>\n",
       "      <td>LANDO</td>\n",
       "      <td>Wedge, I dont think were going to make it.</td>\n",
       "      <td>episode VI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2519</th>\n",
       "      <td>WEDGE</td>\n",
       "      <td>Youll make it. Just follow me Gold Leader.</td>\n",
       "      <td>episode VI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2520</th>\n",
       "      <td>LANDO</td>\n",
       "      <td>I promised to return his ship without a scratc...</td>\n",
       "      <td>episode VI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2521</th>\n",
       "      <td>HAN</td>\n",
       "      <td>Lando...</td>\n",
       "      <td>episode VI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2522</th>\n",
       "      <td>THREEPIO</td>\n",
       "      <td>They did it</td>\n",
       "      <td>episode VI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2523 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     character_                                              text_     episode\n",
       "0      THREEPIO  Did you hear that  Theyve shut down the main r...  episode IV\n",
       "1      THREEPIO                                        Were doomed  episode IV\n",
       "2      THREEPIO   Therell be no escape for the Princess this time.  episode IV\n",
       "3      THREEPIO                                         Whats that  episode IV\n",
       "4      THREEPIO  I should have known better than to trust the l...  episode IV\n",
       "...         ...                                                ...         ...\n",
       "2518      LANDO         Wedge, I dont think were going to make it.  episode VI\n",
       "2519      WEDGE         Youll make it. Just follow me Gold Leader.  episode VI\n",
       "2520      LANDO  I promised to return his ship without a scratc...  episode VI\n",
       "2521        HAN                                           Lando...  episode VI\n",
       "2522   THREEPIO                                        They did it  episode VI\n",
       "\n",
       "[2523 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"SELECT * FROM dialogue\"\n",
    "df = pd.read_sql_query(query, engine)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4980328d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPERIAL O\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[10][\"character_\"][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf32a63",
   "metadata": {},
   "source": [
    "### NLP "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4b274e",
   "metadata": {},
   "source": [
    "### Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d6fa182c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NLP' object has no attribute 'Defaults'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [55]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m stop \u001b[38;5;241m=\u001b[39m \u001b[43mnlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDefaults\u001b[49m\u001b[38;5;241m.\u001b[39mstopwords\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NLP' object has no attribute 'Defaults'"
     ]
    }
   ],
   "source": [
    "stop = nlp.Defaults.stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e510512f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_list = []\n",
    "#for element in as_it_was.split(\" \"):\n",
    " #   if element not in stop:\n",
    "  #      new_list.append(element)\n",
    "#string_without_stop = \" \".join(new_list)\n",
    "#print(string_without_stop) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77049591",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "edfba8c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[1;32mIn [37]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m nlp \u001b[38;5;241m=\u001b[39m \u001b[43mspacy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43men_core_web_sm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ironhack\\lib\\site-packages\\spacy\\__init__.py:54\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[0;32m     31\u001b[0m     name: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mSimpleFrozenDict(),\n\u001b[0;32m     38\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Language:\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;124;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \u001b[38;5;124;03m    name (str): Package name or model path.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;124;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ironhack\\lib\\site-packages\\spacy\\util.py:439\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[0;32m    438\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE941\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname, full\u001b[38;5;241m=\u001b[39mOLD_MODEL_SHORTCUTS[name]))  \u001b[38;5;66;03m# type: ignore[index]\u001b[39;00m\n\u001b[1;32m--> 439\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE050\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname))\n",
      "\u001b[1;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be559080",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nlp(string_without_stop)\n",
    "#tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e759f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized = []\n",
    "for token in tokens:\n",
    "    lemmatized.append(token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b760918",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect(\"what is this language\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53203e5b",
   "metadata": {},
   "source": [
    "### We generate a WordCloud of the Episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4c319c06",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '..\\\\df_all_episodes.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [52]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mstylecloud\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen_stylecloud\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m..\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mdf_all_episodes.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                         \u001b[49m\u001b[43micon_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfas fa-dog\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mpalette\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcolorbrewer.diverging.Spectral_11\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mblack\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mgradient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhorizontal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ironhack\\lib\\site-packages\\stylecloud\\stylecloud.py:216\u001b[0m, in \u001b[0;36mgen_stylecloud\u001b[1;34m(text, file_path, size, icon_name, palette, colors, background_color, max_font_size, max_words, stopwords, custom_stopwords, add_stopwords, icon_dir, output_name, gradient, font_path, random_state, collocations, invert_mask, pro_icon_path, pro_css_path)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28many\u001b[39m([text, file_path]), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEither text or file_path must be specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_path:\n\u001b[1;32m--> 216\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[43mfile_to_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m gen_fa_mask(icon_name, size, icon_dir, pro_icon_path, pro_css_path)\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gradient \u001b[38;5;129;01mand\u001b[39;00m colors \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ironhack\\lib\\site-packages\\stylecloud\\stylecloud.py:28\u001b[0m, in \u001b[0;36mfile_to_text\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m text\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# parse as a CSV\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     29\u001b[0m         r \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mreader(f)\n\u001b[0;32m     30\u001b[0m         header \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(r)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '..\\\\df_all_episodes.csv'"
     ]
    }
   ],
   "source": [
    "stylecloud.gen_stylecloud(file_path='..\\df_all_episodes.csv',\n",
    "                         icon_name='fas fa-dog',\n",
    "                          palette='colorbrewer.diverging.Spectral_11',\n",
    "                          background_color='black',\n",
    "                          gradient='horizontal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682c6e5e",
   "metadata": {},
   "source": [
    "### Sentiment analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2e7f8501",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\rapha\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.downloader.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5367c6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2ab1c4c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'encode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [41]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msia\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolarity_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ironhack\\lib\\site-packages\\nltk\\sentiment\\vader.py:361\u001b[0m, in \u001b[0;36mSentimentIntensityAnalyzer.polarity_scores\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;124;03mReturn a float for sentiment strength based on the input text.\u001b[39;00m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;124;03mPositive values are positive valence, negative value are negative\u001b[39;00m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;124;03mvalence.\u001b[39;00m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;66;03m# text, words_and_emoticons, is_cap_diff = self.preprocess(text)\u001b[39;00m\n\u001b[1;32m--> 361\u001b[0m sentitext \u001b[38;5;241m=\u001b[39m \u001b[43mSentiText\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstants\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPUNC_LIST\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstants\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREGEX_REMOVE_PUNCTUATION\u001b[49m\n\u001b[0;32m    363\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    364\u001b[0m sentiments \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    365\u001b[0m words_and_emoticons \u001b[38;5;241m=\u001b[39m sentitext\u001b[38;5;241m.\u001b[39mwords_and_emoticons\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ironhack\\lib\\site-packages\\nltk\\sentiment\\vader.py:270\u001b[0m, in \u001b[0;36mSentiText.__init__\u001b[1;34m(self, text, punc_list, regex_remove_punctuation)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, text, punc_list, regex_remove_punctuation):\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(text, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 270\u001b[0m         text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[43mtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;241m=\u001b[39m text\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mPUNC_LIST \u001b[38;5;241m=\u001b[39m punc_list\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ironhack\\lib\\site-packages\\pandas\\core\\generic.py:5902\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5895\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   5896\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   5897\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   5898\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   5899\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5900\u001b[0m ):\n\u001b[0;32m   5901\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 5902\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'encode'"
     ]
    }
   ],
   "source": [
    "sia.polarity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d8af8a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character_</th>\n",
       "      <th>text_</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>THREEPIO</td>\n",
       "      <td>Did you hear that  Theyve shut down the main r...</td>\n",
       "      <td>0.249</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.180</td>\n",
       "      <td>-0.4019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>THREEPIO</td>\n",
       "      <td>Were doomed</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.6369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>THREEPIO</td>\n",
       "      <td>Therell be no escape for the Princess this time.</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.156</td>\n",
       "      <td>-0.1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>THREEPIO</td>\n",
       "      <td>Whats that</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>THREEPIO</td>\n",
       "      <td>I should have known better than to trust the l...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.7351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2518</th>\n",
       "      <td>LANDO</td>\n",
       "      <td>Wedge, I dont think were going to make it.</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2519</th>\n",
       "      <td>WEDGE</td>\n",
       "      <td>Youll make it. Just follow me Gold Leader.</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2520</th>\n",
       "      <td>LANDO</td>\n",
       "      <td>I promised to return his ship without a scratc...</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.2100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2521</th>\n",
       "      <td>HAN</td>\n",
       "      <td>Lando...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2522</th>\n",
       "      <td>THREEPIO</td>\n",
       "      <td>They did it</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2523 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     character_                                              text_    neg  \\\n",
       "0      THREEPIO  Did you hear that  Theyve shut down the main r...  0.249   \n",
       "1      THREEPIO                                        Were doomed  0.808   \n",
       "2      THREEPIO   Therell be no escape for the Princess this time.  0.202   \n",
       "3      THREEPIO                                         Whats that  0.000   \n",
       "4      THREEPIO  I should have known better than to trust the l...  0.000   \n",
       "...         ...                                                ...    ...   \n",
       "2518      LANDO         Wedge, I dont think were going to make it.  0.000   \n",
       "2519      WEDGE         Youll make it. Just follow me Gold Leader.  0.000   \n",
       "2520      LANDO  I promised to return his ship without a scratc...  0.223   \n",
       "2521        HAN                                           Lando...  0.000   \n",
       "2522   THREEPIO                                        They did it  0.000   \n",
       "\n",
       "        neu    pos  compound  \n",
       "0     0.571  0.180   -0.4019  \n",
       "1     0.192  0.000   -0.6369  \n",
       "2     0.642  0.156   -0.1280  \n",
       "3     1.000  0.000    0.0000  \n",
       "4     0.659  0.341    0.7351  \n",
       "...     ...    ...       ...  \n",
       "2518  1.000  0.000    0.0000  \n",
       "2519  1.000  0.000    0.0000  \n",
       "2520  0.511  0.266    0.2100  \n",
       "2521  1.000  0.000    0.0000  \n",
       "2522  1.000  0.000    0.0000  \n",
       "\n",
       "[2523 rows x 6 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wragling data\n",
    "df_avatar_lines = df.groupby('character_').count()\n",
    "df_avatar_lines = df.sort_values(by=['text_'], ascending=False)[:10]\n",
    "top_character_names = df.index.values\n",
    "\n",
    "# filtering out non-top characters\n",
    "df_character_sentiment = df[df['character_'].isin(top_character_names)]\n",
    "df_character_sentiment = df[['character_', 'text_']]\n",
    "\n",
    "# calculating sentiment score\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "df_character_sentiment.reset_index(inplace=True, drop=True)\n",
    "df_character_sentiment[['neg', 'neu', 'pos', 'compound']] = df_character_sentiment['text_'].apply(sid.polarity_scores).apply(pd.Series)\n",
    "df_character_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15211f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ironhack",
   "language": "python",
   "name": "ironhack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
